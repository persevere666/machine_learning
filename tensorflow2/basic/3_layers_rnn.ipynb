{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.RNN\n",
    "```\n",
    "tf.keras.layers.RNN(\n",
    "    cell,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    "    zero_output_for_mask=False,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "* args\n",
    "  - cell  \n",
    "    A RNN cell instance or a list of RNN cell instances\n",
    "    \n",
    "  - \n",
    "* Input shape:\n",
    "    3-D tensor with shape `(batch_size, timesteps, features)`.\n",
    "\n",
    "* Output shape:\n",
    "    - If `return_state`: a list of tensors. The first tensor is\n",
    "    the output. The remaining tensors are the last states,\n",
    "    each with shape `(batch_size, state_size)`, where `state_size` could\n",
    "    be a high dimension tensor shape.\n",
    "    - If `return_sequences`: 3D tensor with shape\n",
    "    `(batch_size, timesteps, output_size)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # self.units = units\n",
    "        self.state_size = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"input_shape={}\".format(input_shape))\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.state_size),\n",
    "                                        initializer='uniform',\n",
    "                                        name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.state_size, self.state_size),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = tf.keras.ops.matmul(inputs, self.kernel)\n",
    "        output = h + tf.keras.ops.matmul(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=(None, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_82 (\u001b[38;5;33mRNN\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,184\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,184</span> (4.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,184\u001b[0m (4.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,184</span> (4.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,184\u001b[0m (4.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cell = MinimalRNNCell(32)\n",
    "x = tf.keras.Input(shape=(None,5))\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "y = layer(x)\n",
    "model = tf.keras.Model(inputs=x,outputs=y)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 5)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.random.normal((3,2,5))\n",
    "print(data.shape)\n",
    "output = model.predict(x=data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32)\n",
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "weights, bias = layer.get_weights()\n",
    "tf.print(weights.shape)\n",
    "tf.print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=(None, 5)\n",
      "input_shape=(None, 32)\n"
     ]
    }
   ],
   "source": [
    "cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
    "x = tf.keras.Input((None, 5))\n",
    "layer = tf.keras.layers.RNN(cells)\n",
    "y = layer(x)\n",
    "model = tf.keras.Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.random.normal((3,2,5))\n",
    "print(data.shape)\n",
    "output = model.predict(x=data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.LSTMCell\n",
    "```\n",
    "    tf.keras.layers.LSTMCell(\n",
    "        units,\n",
    "        activation='tanh',\n",
    "        recurrent_activation='sigmoid',\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        recurrent_initializer='orthogonal',\n",
    "        bias_initializer='zeros',\n",
    "        unit_forget_bias=True,\n",
    "        kernel_regularizer=None,\n",
    "        recurrent_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        recurrent_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        dropout=0.0,\n",
    "        recurrent_dropout=0.0,\n",
    "        seed=None,\n",
    "        **kwargs\n",
    "    )\n",
    "    Call arguments:\n",
    "        inputs: A 2D tensor, with shape `(batch, features)`.\n",
    "        states: A 2D tensor with shape `(batch, units)`, which is the state\n",
    "            from the previous time step.\n",
    "        training: Python boolean indicating whether the layer should behave in\n",
    "            training mode or in inference mode. Only relevant when `dropout` or\n",
    "            `recurrent_dropout` is used.\n",
    "    权重\n",
    "        kernel shape =(input_dim, self.units * 4)\n",
    "        recurrent_kernel shape=(self.units, self.units * 4)\n",
    "        bias shape =(self.units * 4,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 0.552522  , -0.38236696, -0.2097214 ],\n",
       "       [ 0.57467663, -0.38092893, -0.23813564]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((2,10,8))\n",
    "rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(3))\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(3), return_sequences=False, return_state=True)\n",
    "final_output,state_h,state_c = rnn2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3621279 -0.396188468 -0.0788854212]\n",
      " [0.438182026 -0.407655537 0.00722320285]]\n",
      "[[0.3621279 -0.396188468 -0.0788854212]\n",
      " [0.438182026 -0.407655537 0.00722320285]]\n",
      "[[1.13227391 -0.673898697 -0.130918488]\n",
      " [1.05494821 -0.825320661 0.0146492561]]\n"
     ]
    }
   ],
   "source": [
    "tf.print(final_output)\n",
    "tf.print(state_h)\n",
    "tf.print(state_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12)\n",
      "(3, 12)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "# kernel shape =(input_dim, self.units * 4)\n",
    "# recurrent_kernel shape=(self.units, self.units * 4)\n",
    "# bias shape =(self.units * 4,)\n",
    "kernel,recurrent_kernel,bias = rnn.get_weights()\n",
    "print(kernel.shape)\n",
    "print(recurrent_kernel.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.LSTM\n",
    "LSTM继承了tf.keras.layers.RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 3, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.random((2, 3, 4))\n",
    "lstm = tf.keras.layers.LSTM(5)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(5, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n",
    "print(final_carry_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20)\n",
      "(5, 20)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "kernel_lstm, recurrent_kernel_lstm, bias_lstm = lstm.get_weights()\n",
    "print(kernel_lstm.shape)\n",
    "print(recurrent_kernel_lstm.shape)\n",
    "print(bias_lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.GRUCell\n",
    "```\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        recurrent_initializer=\"orthogonal\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        recurrent_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        recurrent_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        dropout=0.0,\n",
    "        recurrent_dropout=0.0,\n",
    "        reset_after=True,\n",
    "        seed=None,\n",
    "        **kwargs,\n",
    "    )\n",
    "    Call arguments:\n",
    "        inputs: A 2D tensor, with shape `(batch, features)`.\n",
    "        states: A 2D tensor with shape `(batch, units)`, which is the state\n",
    "            from the previous time step.\n",
    "        training: Python boolean indicating whether the layer should behave in\n",
    "            training mode or in inference mode. Only relevant when `dropout` or\n",
    "            `recurrent_dropout` is used.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[-0.14473268,  0.28370684, -0.14832309,  0.12082352, -0.22530709],\n",
       "       [-0.31083363,  0.26357356, -0.38767987, -0.28236735,  0.14880402]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.random.random((2,3,4))\n",
    "gru = tf.keras.layers.GRUCell(5)\n",
    "rnn1 = tf.keras.layers.RNN(gru)\n",
    "rnn1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = tf.keras.layers.RNN(gru,return_sequences=True,return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       " array([[[-0.16979632,  0.17237757, -0.18382923, -0.20845969,\n",
       "           0.01840987],\n",
       "         [-0.14016089,  0.1289713 , -0.1722104 , -0.03224351,\n",
       "           0.03292613],\n",
       "         [-0.14473268,  0.28370684, -0.14832309,  0.12082352,\n",
       "          -0.22530709]],\n",
       " \n",
       "        [[-0.12160186,  0.16266301, -0.17113881, -0.15289839,\n",
       "           0.00720164],\n",
       "         [-0.22395606,  0.30100536, -0.3007007 , -0.22977392,\n",
       "           0.02138322],\n",
       "         [-0.31083363,  0.26357356, -0.38767987, -0.28236735,\n",
       "           0.14880402]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       " array([[-0.14473268,  0.28370684, -0.14832309,  0.12082352, -0.22530709],\n",
       "        [-0.31083363,  0.26357356, -0.38767987, -0.28236735,  0.14880402]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 15)\n",
      "(5, 15)\n",
      "(2, 15)\n"
     ]
    }
   ],
   "source": [
    "kernel_gru, recurrent_kernel_gru, bias_gru = rnn2.get_weights()\n",
    "print(kernel_gru.shape)\n",
    "print(recurrent_kernel_gru.shape)\n",
    "# separate biases for input and recurrent kernels\n",
    "print(bias_gru.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.GRU\n",
    "继承了tf.keras.layers.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.random((2, 10, 8))\n",
    "gru1 = tf.keras.layers.GRU(4)\n",
    "output = gru1(inputs)\n",
    "output.shape\n",
    "\n",
    "gru2 = tf.keras.layers.GRU(4, return_sequences=True, return_state=False)\n",
    "whole_sequence_output = gru2(inputs)\n",
    "print(whole_sequence_output.shape)\n",
    "#print(final_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.42748457,  0.55501944,  0.2937019 , -0.06797385],\n",
       "       [-0.03309484,  0.47437924,  0.29864812, -0.5828115 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.42748457,  0.55501944,  0.2937019 , -0.06797385],\n",
       "       [-0.03309484,  0.47437924,  0.29864812, -0.5828115 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.Bidirectional\n",
    "```\n",
    "tf.keras.layers.Bidirectional(\n",
    "    layer,\n",
    "    merge_mode='concat',\n",
    "    weights=None,\n",
    "    backward_layer=None,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "def call(\n",
    "    self,\n",
    "    sequences,\n",
    "    initial_state=None,\n",
    "    mask=None,\n",
    "    training=None,\n",
    ")\n",
    "\n",
    "Args:\n",
    "    layer: `keras.layers.RNN` instance, such as\n",
    "        `keras.layers.LSTM` or `keras.layers.GRU`.\n",
    "        It could also be a `keras.layers.Layer` instance\n",
    "        that meets the following criteria:\n",
    "        1. Be a sequence-processing layer (accepts 3D+ inputs).\n",
    "        2. Have a `go_backwards`, `return_sequences` and `return_state`\n",
    "        attribute (with the same semantics as for the `RNN` class).\n",
    "        3. Have an `input_spec` attribute.\n",
    "        4. Implement serialization via `get_config()` and `from_config()`.\n",
    "        Note that the recommended way to create new RNN layers is to write a\n",
    "        custom RNN cell and use it with `keras.layers.RNN`, instead of\n",
    "        subclassing `keras.layers.Layer` directly.\n",
    "        When `return_sequences` is `True`, the output of the masked\n",
    "        timestep will be zero regardless of the layer's original\n",
    "        `zero_output_for_mask` value.\n",
    "    merge_mode: Mode by which outputs of the forward and backward RNNs\n",
    "        will be combined. One of `{\"sum\", \"mul\", \"concat\", \"ave\", None}`.\n",
    "        If `None`, the outputs will not be combined,\n",
    "        they will be returned as a list. Defaults to `\"concat\"`.\n",
    "    backward_layer: Optional `keras.layers.RNN`,\n",
    "        or `keras.layers.Layer` instance to be used to handle\n",
    "        backwards input processing.\n",
    "        If `backward_layer` is not provided, the layer instance passed\n",
    "        as the `layer` argument will be used to generate the backward layer\n",
    "        automatically.\n",
    "        Note that the provided `backward_layer` layer should have properties\n",
    "        matching those of the `layer` argument, in particular\n",
    "        it should have the same values for `stateful`, `return_states`,\n",
    "        `return_sequences`, etc. In addition, `backward_layer`\n",
    "        and `layer` should have different `go_backwards` argument values.\n",
    "        A `ValueError` will be raised if these requirements are not met.\n",
    "\n",
    "Call arguments:\n",
    "    The call arguments for this layer are the same as those of the\n",
    "    wrapped RNN layer. Beware that when passing the `initial_state`\n",
    "    argument during the call of this layer, the first half in the\n",
    "    list of elements in the `initial_state` list will be passed to\n",
    "    the forward RNN call and the last half in the list of elements\n",
    "    will be passed to the backward RNN call.\n",
    "\n",
    "Note: instantiating a `Bidirectional` layer from an existing RNN layer\n",
    "instance will not reuse the weights state of the RNN layer instance -- the\n",
    "`Bidirectional` layer will have freshly initialized weights.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │           \u001b[38;5;34m816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m720\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m44\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,580</span> (6.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,580\u001b[0m (6.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,580</span> (6.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,580\u001b[0m (6.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28301755, 0.26528645, 0.21479882, 0.23689722],\n",
       "       [0.27503747, 0.26902932, 0.2097223 , 0.2462109 ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(5,10)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(6,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5,return_sequences=False)),\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"Dice\")\n",
    "model.summary()\n",
    "x=np.random.random((2,5,10))\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_17                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_17                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)       │           \u001b[38;5;34m440\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │            \u001b[38;5;34m44\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484</span> (1.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m484\u001b[0m (1.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484</span> (1.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m484\u001b[0m (1.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forward_layer = tf.keras.layers.LSTM(5,return_sequences=True)\n",
    "backward_layer = tf.keras.layers.LSTM(5, return_sequences=True, go_backwards=True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((None,5)),\n",
    "    tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.65419205, 0.76972482, 0.51887192, 0.00993751, 0.01756697],\n",
      "       [0.03755188, 0.92278993, 0.80396395, 0.05055183, 0.08868134],\n",
      "       [0.78110225, 0.95311067, 0.43463611, 0.40639844, 0.77907658]]), array([[0.66915554, 0.82877664, 0.55386778, 0.22147299, 0.86445864],\n",
      "       [0.97277951, 0.84327059, 0.81434158, 0.1252304 , 0.55577839],\n",
      "       [0.3836112 , 0.16558977, 0.28735023, 0.83252969, 0.51942957]])]\n",
      "(2, 3, 5)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x1 = np.random.random((3,5))\n",
    "    x2 = np.random.random((3,5))\n",
    "    x = [x1,x2]\n",
    "    print(x)\n",
    "    x = np.stack([x1,x2], axis=0)\n",
    "    print(x.shape)\n",
    "    model.predict(x)\n",
    "except ValueError as e:\n",
    "    print(\"error\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
