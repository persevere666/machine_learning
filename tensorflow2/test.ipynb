{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d975aacc-490a-4e02-be9a-505dc6887c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 12:49:44.651425: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a811bb3c-9e87-4b7e-90e7-65df863ba2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haha\n"
     ]
    }
   ],
   "source": [
    "PLAIN_TYPES = (str, int, float, bool)\n",
    "def serialize_keras_object(obj):\n",
    "    if isinstance(obj,PLAIN_TYPES):\n",
    "        print(\"haha\")\n",
    "    else:\n",
    "        print(\"heihei\")\n",
    "serialize_keras_object(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdadc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '2': 2, '3': 3, '4': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_config():\n",
    "    config1 = {\n",
    "        \"1\":1,\n",
    "        \"2\":2\n",
    "    }\n",
    "    config2 = {\n",
    "        \"3\":3,\n",
    "        \"4\":4\n",
    "    }\n",
    "    return {**config1,**config2}\n",
    "get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291ba83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.convert_to_tensor([1,2,3,4])\n",
    "keras.tree.is_nested(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9bf13da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 3), 2, 3, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = (1,2,3)\n",
    "list2 = (2,3,4)\n",
    "tuple(list1) + tuple(list2)\n",
    "(list1,) + list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f783213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 2, 3, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 + list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe8e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddec6d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ThisIsATest'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ThisIsATest:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "obj = ThisIsATest()\n",
    "obj.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "759b202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.losses import Loss\n",
    "\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.losses import BinaryFocalCrossentropy\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.losses import CategoricalFocalCrossentropy\n",
    "from keras.losses import CategoricalHinge\n",
    "from keras.losses import CosineSimilarity\n",
    "#from keras.losses import Dice\n",
    "from keras.losses import Hinge\n",
    "from keras.losses import Huber\n",
    "from keras.losses import KLDivergence\n",
    "from keras.losses import LogCosh\n",
    "#from keras.losses import LossFunctionWrapper\n",
    "from keras.losses import MeanAbsoluteError\n",
    "from keras.losses import MeanAbsolutePercentageError\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.losses import MeanSquaredLogarithmicError\n",
    "from keras.losses import Poisson\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.losses import SquaredHinge\n",
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.losses import binary_focal_crossentropy\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.losses import categorical_focal_crossentropy\n",
    "from keras.losses import categorical_hinge\n",
    "from keras.losses import cosine_similarity\n",
    "from keras.losses import ctc\n",
    "#from keras.losses import dice\n",
    "\n",
    "from keras.losses import hinge\n",
    "from keras.losses import huber\n",
    "from keras.losses import kl_divergence\n",
    "from keras.losses import log_cosh\n",
    "from keras.losses import mean_absolute_error\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.losses import mean_squared_logarithmic_error\n",
    "from keras.losses import poisson\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.losses import squared_hinge\n",
    "\n",
    "ALL_OBJECTS = {\n",
    "    # Base\n",
    "    Loss,\n",
    "    #LossFunctionWrapper,\n",
    "    # Probabilistic\n",
    "    KLDivergence,\n",
    "    Poisson,\n",
    "    BinaryCrossentropy,\n",
    "    BinaryFocalCrossentropy,\n",
    "    CategoricalCrossentropy,\n",
    "    CategoricalFocalCrossentropy,\n",
    "    SparseCategoricalCrossentropy,\n",
    "    # Regression\n",
    "    MeanSquaredError,\n",
    "    MeanAbsoluteError,\n",
    "    MeanAbsolutePercentageError,\n",
    "    MeanSquaredLogarithmicError,\n",
    "    CosineSimilarity,\n",
    "    LogCosh,\n",
    "    Huber,\n",
    "    # Hinge\n",
    "    Hinge,\n",
    "    SquaredHinge,\n",
    "    CategoricalHinge,\n",
    "    # Image segmentation\n",
    "    #Dice,\n",
    "    # Probabilistic\n",
    "    kl_divergence,\n",
    "    poisson,\n",
    "    binary_crossentropy,\n",
    "    binary_focal_crossentropy,\n",
    "    categorical_crossentropy,\n",
    "    categorical_focal_crossentropy,\n",
    "    sparse_categorical_crossentropy,\n",
    "    # Regression\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_logarithmic_error,\n",
    "    cosine_similarity,\n",
    "    log_cosh,\n",
    "    huber,\n",
    "    # Hinge\n",
    "    hinge,\n",
    "    squared_hinge,\n",
    "    categorical_hinge,\n",
    "    # Image segmentation\n",
    "    #dice,\n",
    "}\n",
    "\n",
    "ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n",
    "ALL_OBJECTS_DICT.update(\n",
    "    {\n",
    "        \"bce\": binary_crossentropy,\n",
    "        \"BCE\": binary_crossentropy,\n",
    "        \"kld\": kl_divergence,\n",
    "        \"KLD\": kl_divergence,\n",
    "        \"mae\": mean_absolute_error,\n",
    "        \"MAE\": mean_absolute_error,\n",
    "        \"mse\": mean_squared_error,\n",
    "        \"MSE\": mean_squared_error,\n",
    "        \"mape\": mean_absolute_percentage_error,\n",
    "        \"MAPE\": mean_absolute_percentage_error,\n",
    "        \"msle\": mean_squared_logarithmic_error,\n",
    "        \"MSLE\": mean_squared_logarithmic_error,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc198c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFocalCrossentropy <class 'keras.src.losses.losses.BinaryFocalCrossentropy'>\n",
      "squared_hinge <function squared_hinge at 0x128804860>\n",
      "sparse_categorical_crossentropy <function sparse_categorical_crossentropy at 0x128805080>\n",
      "KLDivergence <class 'keras.src.losses.losses.KLDivergence'>\n",
      "categorical_hinge <function categorical_hinge at 0x128804900>\n",
      "binary_crossentropy <function binary_crossentropy at 0x128805120>\n",
      "mean_squared_error <function mean_squared_error at 0x1288049a0>\n",
      "CosineSimilarity <class 'keras.src.losses.losses.CosineSimilarity'>\n",
      "binary_focal_crossentropy <function binary_focal_crossentropy at 0x1288051c0>\n",
      "MeanAbsolutePercentageError <class 'keras.src.losses.losses.MeanAbsolutePercentageError'>\n",
      "mean_absolute_error <function mean_absolute_error at 0x128804a40>\n",
      "MeanSquaredError <class 'keras.src.losses.losses.MeanSquaredError'>\n",
      "Loss <class 'keras.src.losses.loss.Loss'>\n",
      "LogCosh <class 'keras.src.losses.losses.LogCosh'>\n",
      "mean_absolute_percentage_error <function mean_absolute_percentage_error at 0x128804ae0>\n",
      "MeanAbsoluteError <class 'keras.src.losses.losses.MeanAbsoluteError'>\n",
      "Huber <class 'keras.src.losses.losses.Huber'>\n",
      "mean_squared_logarithmic_error <function mean_squared_logarithmic_error at 0x128804b80>\n",
      "cosine_similarity <function cosine_similarity at 0x128804c20>\n",
      "huber <function huber at 0x128804cc0>\n",
      "SquaredHinge <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "log_cosh <function log_cosh at 0x128804d60>\n",
      "MeanSquaredLogarithmicError <class 'keras.src.losses.losses.MeanSquaredLogarithmicError'>\n",
      "kl_divergence <function kl_divergence at 0x128804e00>\n",
      "Hinge <class 'keras.src.losses.losses.Hinge'>\n",
      "SparseCategoricalCrossentropy <class 'keras.src.losses.losses.SparseCategoricalCrossentropy'>\n",
      "BinaryCrossentropy <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "CategoricalHinge <class 'keras.src.losses.losses.CategoricalHinge'>\n",
      "poisson <function poisson at 0x128804ea0>\n",
      "CategoricalCrossentropy <class 'keras.src.losses.losses.CategoricalCrossentropy'>\n",
      "categorical_crossentropy <function categorical_crossentropy at 0x128804f40>\n",
      "CategoricalFocalCrossentropy <class 'keras.src.losses.losses.CategoricalFocalCrossentropy'>\n",
      "Poisson <class 'keras.src.losses.losses.Poisson'>\n",
      "hinge <function hinge at 0x1288047c0>\n",
      "categorical_focal_crossentropy <function categorical_focal_crossentropy at 0x128804fe0>\n",
      "bce <function binary_crossentropy at 0x128805120>\n",
      "BCE <function binary_crossentropy at 0x128805120>\n",
      "kld <function kl_divergence at 0x128804e00>\n",
      "KLD <function kl_divergence at 0x128804e00>\n",
      "mae <function mean_absolute_error at 0x128804a40>\n",
      "MAE <function mean_absolute_error at 0x128804a40>\n",
      "mse <function mean_squared_error at 0x1288049a0>\n",
      "MSE <function mean_squared_error at 0x1288049a0>\n",
      "mape <function mean_absolute_percentage_error at 0x128804ae0>\n",
      "MAPE <function mean_absolute_percentage_error at 0x128804ae0>\n",
      "msle <function mean_squared_logarithmic_error at 0x128804b80>\n",
      "MSLE <function mean_squared_logarithmic_error at 0x128804b80>\n"
     ]
    }
   ],
   "source": [
    "for key, value in ALL_OBJECTS_DICT.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb8b31ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[0.35296089, 0.24586719, 0.76301279],\n",
       "       [0.95401386, 0.04427627, 0.29244899]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((2,3,1))\n",
    "tf.squeeze(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50545a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "x = [[1,2,0,-1,5],[0,3,2,2,4]]\n",
    "x = np.array(x)\n",
    "x = x.reshape(-1)\n",
    "batch_size = x.shape[0]\n",
    "categorical = np.zeros((batch_size, num_classes), dtype=\"float32\")\n",
    "valid_indices = x >= 0\n",
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b69c57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1 = np.arange(batch_size)[valid_indices]\n",
    "index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8702b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 4, 5, 0, 3, 2, 2, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62157fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical[np.arange(batch_size)[valid_indices], x[valid_indices]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945711f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
